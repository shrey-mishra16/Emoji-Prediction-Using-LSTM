{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /home/shrey/test_tensorflow_gpu/venv/lib/python3.7/site-packages (0.5.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòû\n",
      "üç¥\n",
      "üëÖ\n",
      "üï∂\n",
      "üíè\n",
      ":poop:\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":grinning_face_with_big_eyes:\",\n",
    "                    \"3\": \":disappointed_face:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "                    \"5\": \":tongue:\",\n",
    "                    \"6\": \":sunglasses:\",\n",
    "                    \"7\": \":kiss:\",\n",
    "                    \"8\": \":poop:\",\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"./dataset/train_emoji.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"./dataset/test_emoji.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train[0]\n",
    "Y_train=train[1]\n",
    "X_test=test[0]\n",
    "Y_test=test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(X_train[i],emoji.emojize(emoji_dictionary[str(Y_train[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('./dataset/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index={}\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=np.asarray(values[1:],dtype=\"float\")\n",
    "    embeddings_index[word]=coefs\n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(X):\n",
    "    maxLen=10\n",
    "    emb_dim=50\n",
    "    embedding_op=np.zeros((X.shape[0],maxLen,50))\n",
    "    \n",
    "    for ix in range(X.shape[0]):\n",
    "        X[ix]=X[ix].split()\n",
    "        for ij in range(len(X[ix])):\n",
    "            try:\n",
    "                embedding_op[ix][ij]=embeddings_index[X[ix][ij].lower()]\n",
    "            except:\n",
    "                embedding_op[ix][ij]=np.zeros((50,))\n",
    "    return embedding_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrey/.local/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "emb_matrix_train=embedding_output(X_train)\n",
    "emb_matrix_test=embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=to_categorical(Y_train,num_classes=5)\n",
    "Y_test=to_categorical(Y_test,num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 1.5949 - accuracy: 0.2762 - val_loss: 1.5999 - val_accuracy: 0.1852\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 204us/step - loss: 1.5687 - accuracy: 0.2667 - val_loss: 1.5996 - val_accuracy: 0.2593\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 249us/step - loss: 1.5361 - accuracy: 0.3429 - val_loss: 1.6080 - val_accuracy: 0.2222\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 232us/step - loss: 1.5104 - accuracy: 0.3333 - val_loss: 1.6178 - val_accuracy: 0.2222\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 275us/step - loss: 1.4748 - accuracy: 0.2952 - val_loss: 1.6337 - val_accuracy: 0.2222\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 276us/step - loss: 1.4788 - accuracy: 0.3143 - val_loss: 1.6452 - val_accuracy: 0.2222\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 239us/step - loss: 1.4703 - accuracy: 0.3429 - val_loss: 1.6486 - val_accuracy: 0.2593\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 272us/step - loss: 1.4304 - accuracy: 0.3619 - val_loss: 1.6309 - val_accuracy: 0.2593\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 257us/step - loss: 1.4251 - accuracy: 0.3905 - val_loss: 1.6072 - val_accuracy: 0.1481\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 301us/step - loss: 1.3953 - accuracy: 0.4190 - val_loss: 1.5746 - val_accuracy: 0.2593\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 232us/step - loss: 1.3409 - accuracy: 0.4190 - val_loss: 1.5373 - val_accuracy: 0.2963\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 264us/step - loss: 1.3113 - accuracy: 0.4667 - val_loss: 1.4967 - val_accuracy: 0.3333\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 1.2967 - accuracy: 0.5143 - val_loss: 1.4505 - val_accuracy: 0.3704\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 280us/step - loss: 1.2293 - accuracy: 0.6190 - val_loss: 1.4093 - val_accuracy: 0.3704\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 255us/step - loss: 1.1850 - accuracy: 0.6095 - val_loss: 1.3790 - val_accuracy: 0.3704\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 250us/step - loss: 1.1458 - accuracy: 0.6190 - val_loss: 1.3632 - val_accuracy: 0.3333\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 243us/step - loss: 1.0814 - accuracy: 0.6286 - val_loss: 1.3411 - val_accuracy: 0.3704\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 263us/step - loss: 1.0358 - accuracy: 0.6286 - val_loss: 1.2677 - val_accuracy: 0.5185\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 287us/step - loss: 0.9380 - accuracy: 0.7238 - val_loss: 1.2018 - val_accuracy: 0.4444\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 263us/step - loss: 0.8669 - accuracy: 0.7429 - val_loss: 1.1901 - val_accuracy: 0.4815\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 271us/step - loss: 0.7757 - accuracy: 0.7238 - val_loss: 1.1928 - val_accuracy: 0.4444\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 306us/step - loss: 0.7456 - accuracy: 0.7905 - val_loss: 1.1396 - val_accuracy: 0.5185\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 253us/step - loss: 0.7095 - accuracy: 0.7714 - val_loss: 1.0488 - val_accuracy: 0.5556\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 233us/step - loss: 0.7077 - accuracy: 0.7810 - val_loss: 1.0758 - val_accuracy: 0.5926\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 272us/step - loss: 0.6291 - accuracy: 0.8286 - val_loss: 1.1166 - val_accuracy: 0.6296\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 252us/step - loss: 0.6069 - accuracy: 0.7905 - val_loss: 1.0615 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 262us/step - loss: 0.5050 - accuracy: 0.8286 - val_loss: 0.9924 - val_accuracy: 0.7407\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 279us/step - loss: 0.4621 - accuracy: 0.8667 - val_loss: 1.1206 - val_accuracy: 0.7037\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 232us/step - loss: 0.5049 - accuracy: 0.8381 - val_loss: 1.1749 - val_accuracy: 0.6296\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 310us/step - loss: 0.4266 - accuracy: 0.8571 - val_loss: 1.0389 - val_accuracy: 0.6296\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 245us/step - loss: 0.4420 - accuracy: 0.8571 - val_loss: 1.0066 - val_accuracy: 0.6296\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 292us/step - loss: 0.3921 - accuracy: 0.8667 - val_loss: 1.1390 - val_accuracy: 0.6296\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.3987 - accuracy: 0.8667 - val_loss: 1.2726 - val_accuracy: 0.6296\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 241us/step - loss: 0.3767 - accuracy: 0.8857 - val_loss: 1.1359 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 274us/step - loss: 0.3208 - accuracy: 0.8857 - val_loss: 0.9968 - val_accuracy: 0.5926\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 290us/step - loss: 0.3295 - accuracy: 0.9143 - val_loss: 0.9770 - val_accuracy: 0.6296\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 251us/step - loss: 0.2999 - accuracy: 0.9143 - val_loss: 1.0670 - val_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 260us/step - loss: 0.2180 - accuracy: 0.9429 - val_loss: 1.1260 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 316us/step - loss: 0.2747 - accuracy: 0.8952 - val_loss: 1.0961 - val_accuracy: 0.6296\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 337us/step - loss: 0.2417 - accuracy: 0.9143 - val_loss: 1.1782 - val_accuracy: 0.6296\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 362us/step - loss: 0.2256 - accuracy: 0.9429 - val_loss: 1.3149 - val_accuracy: 0.6296\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 374us/step - loss: 0.1885 - accuracy: 0.9524 - val_loss: 1.4253 - val_accuracy: 0.6296\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 359us/step - loss: 0.1818 - accuracy: 0.9333 - val_loss: 1.3741 - val_accuracy: 0.5926\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 327us/step - loss: 0.1702 - accuracy: 0.9619 - val_loss: 1.2942 - val_accuracy: 0.5926\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 249us/step - loss: 0.1490 - accuracy: 0.9619 - val_loss: 1.3193 - val_accuracy: 0.6296\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 245us/step - loss: 0.1620 - accuracy: 0.9619 - val_loss: 1.4551 - val_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 241us/step - loss: 0.1497 - accuracy: 0.9619 - val_loss: 1.4293 - val_accuracy: 0.6296\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 236us/step - loss: 0.1308 - accuracy: 0.9619 - val_loss: 1.6000 - val_accuracy: 0.5926\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 261us/step - loss: 0.1444 - accuracy: 0.9524 - val_loss: 1.5528 - val_accuracy: 0.6296\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 260us/step - loss: 0.0926 - accuracy: 0.9810 - val_loss: 1.5260 - val_accuracy: 0.6296\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0941 - accuracy: 0.9905 - val_loss: 1.5387 - val_accuracy: 0.5926\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 244us/step - loss: 0.0940 - accuracy: 0.9714 - val_loss: 1.6108 - val_accuracy: 0.5556\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 280us/step - loss: 0.0878 - accuracy: 0.9810 - val_loss: 1.5843 - val_accuracy: 0.5926\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 263us/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 1.4935 - val_accuracy: 0.6296\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 225us/step - loss: 0.0728 - accuracy: 0.9905 - val_loss: 1.4437 - val_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 258us/step - loss: 0.0790 - accuracy: 0.9810 - val_loss: 1.4439 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 253us/step - loss: 0.0751 - accuracy: 0.9714 - val_loss: 1.6229 - val_accuracy: 0.6296\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 252us/step - loss: 0.0889 - accuracy: 0.9714 - val_loss: 1.5928 - val_accuracy: 0.6296\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 241us/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 1.4694 - val_accuracy: 0.6296\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 232us/step - loss: 0.0688 - accuracy: 0.9714 - val_loss: 1.5659 - val_accuracy: 0.6296\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0663 - accuracy: 0.9905 - val_loss: 1.8662 - val_accuracy: 0.5926\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 264us/step - loss: 0.0826 - accuracy: 0.9810 - val_loss: 1.9855 - val_accuracy: 0.5926\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 250us/step - loss: 0.1196 - accuracy: 0.9714 - val_loss: 1.8569 - val_accuracy: 0.5556\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 217us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 1.7603 - val_accuracy: 0.5926\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 257us/step - loss: 0.0680 - accuracy: 0.9810 - val_loss: 1.6828 - val_accuracy: 0.5926\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 214us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.7810 - val_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 226us/step - loss: 0.0521 - accuracy: 0.9905 - val_loss: 1.8275 - val_accuracy: 0.6296\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 217us/step - loss: 0.0510 - accuracy: 0.9905 - val_loss: 1.7510 - val_accuracy: 0.5926\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 232us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.6316 - val_accuracy: 0.6296\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 208us/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.5926\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 225us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.6517 - val_accuracy: 0.6296\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 214us/step - loss: 0.0627 - accuracy: 0.9905 - val_loss: 1.6839 - val_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 251us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.7169 - val_accuracy: 0.6296\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 283us/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.9130 - val_accuracy: 0.5556\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 246us/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 1.8357 - val_accuracy: 0.5556\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 249us/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.7757 - val_accuracy: 0.6296\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 258us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.7855 - val_accuracy: 0.5926\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 241us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.8139 - val_accuracy: 0.5926\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 252us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.8544 - val_accuracy: 0.5926\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 257us/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.8594 - val_accuracy: 0.5556\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 281us/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.9369 - val_accuracy: 0.5556\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 243us/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 1.9606 - val_accuracy: 0.5926\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 242us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.8753 - val_accuracy: 0.5556\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 239us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.8233 - val_accuracy: 0.5926\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 227us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.8096 - val_accuracy: 0.5926\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 251us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.8271 - val_accuracy: 0.5926\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 250us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.8408 - val_accuracy: 0.5926\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 230us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.8372 - val_accuracy: 0.5926\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 267us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.8037 - val_accuracy: 0.5926\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 260us/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 1.8884 - val_accuracy: 0.5556\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.0165 - val_accuracy: 0.6296\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 269us/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.1225 - val_accuracy: 0.6296\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 248us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.2233 - val_accuracy: 0.5556\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 300us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.2575 - val_accuracy: 0.5926\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0257 - accuracy: 0.9905 - val_loss: 2.1297 - val_accuracy: 0.6296\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.0509 - val_accuracy: 0.5556\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0336 - accuracy: 0.9905 - val_loss: 2.0247 - val_accuracy: 0.6296\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 241us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.0285 - val_accuracy: 0.6296\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 226us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.0423 - val_accuracy: 0.6296\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 231us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.0465 - val_accuracy: 0.6296\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "checkpoint=ModelCheckpoint(\"best_model.h5\",monitor='val_loss',verbose=True,save_best_only=True)\n",
    "earlystop=EarlyStopping(monitor='val_accuracy',patience=10)\n",
    "hist=model.fit(emb_matrix_train,Y_train,epochs=100,batch_size=64,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict_classes(emb_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 2 2 2 1 2 4 2 1 2 0 3 1 3 2 2 1 2 0 0 4 2 3 1 2 0 1 2 0 1 2 2 0 2 2\n",
      " 4 1 2 1 0 0 2 2 0 2 2 2 1 3 0 3 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 213us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4341043744768416, 0.5714285969734192]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(emb_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "üç¥\n",
      "üç¥\n",
      "he did not answer\n",
      "üòû\n",
      "üòû\n",
      "he got a raise\n",
      "üòÉ\n",
      "üòÉ\n",
      "she got me a present\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "ha ha ha it was so funny\n",
      "üòÉ\n",
      "üòÉ\n",
      "he is a good friend\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "I am upset\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "We had such a lovely dinner tonight\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "where is the food\n",
      "üç¥\n",
      "üç¥\n",
      "Stop making this joke ha ha ha\n",
      "üòÉ\n",
      "üòÉ\n",
      "where is the ball\n",
      "‚öæ\n",
      "‚öæ\n",
      "work is hard\n",
      "üòû\n",
      "üòÉ\n",
      "This girl is messing with me\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "are you serious ha ha\n",
      "üòÉ\n",
      "üòû\n",
      "Let us go play baseball\n",
      "‚öæ\n",
      "‚öæ\n",
      "This stupid grader is not working\n",
      "üòû\n",
      "üòû\n",
      "work is horrible\n",
      "üòû\n",
      "üòÉ\n",
      "Congratulation for having a baby\n",
      "üòÉ\n",
      "üòÉ\n",
      "stop messing around\n",
      "üòû\n",
      "‚öæ\n",
      "any suggestions for dinner\n",
      "üç¥\n",
      "üòÉ\n",
      "I love taking breaks\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "you brighten my day\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "I boiled rice\n",
      "üç¥\n",
      "üç¥\n",
      "she is a bully\n",
      "üòû\n",
      "üòÉ\n",
      "Why are you feeling bad\n",
      "üòû\n",
      "üòû\n",
      "I am upset\n",
      "üòû\n",
      "‚öæ\n",
      "I worked during my birthday\n",
      "üòû\n",
      "üòÉ\n",
      "My grandmother is the love of my life\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "enjoy your break\n",
      "üòÉ\n",
      "‚öæ\n",
      "valentine day is near\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(' '.join(X_test[i]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(np.argmax(Y_test[i]))]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-1534b7220e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_txt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Love\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"You\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mem_inp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "em_inp=embedding_output(new_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 [I, want, to, eat]\n",
       "1                             [he, did, not, answer]\n",
       "2                                [he, got, a, raise]\n",
       "3                         [she, got, me, a, present]\n",
       "4                   [ha, ha, ha, it, was, so, funny]\n",
       "5                          [he, is, a, good, friend]\n",
       "6                                     [I, am, upset]\n",
       "7        [We, had, such, a, lovely, dinner, tonight]\n",
       "8                             [where, is, the, food]\n",
       "9             [Stop, making, this, joke, ha, ha, ha]\n",
       "10                            [where, is, the, ball]\n",
       "11                                  [work, is, hard]\n",
       "12               [This, girl, is, messing, with, me]\n",
       "13                       [are, you, serious, ha, ha]\n",
       "14                     [Let, us, go, play, baseball]\n",
       "15          [This, stupid, grader, is, not, working]\n",
       "16                              [work, is, horrible]\n",
       "17            [Congratulation, for, having, a, baby]\n",
       "18                           [stop, messing, around]\n",
       "19                   [any, suggestions, for, dinner]\n",
       "20                         [I, love, taking, breaks]\n",
       "21                          [you, brighten, my, day]\n",
       "22                                 [I, boiled, rice]\n",
       "23                               [she, is, a, bully]\n",
       "24                     [Why, are, you, feeling, bad]\n",
       "25                                    [I, am, upset]\n",
       "26                 [I, worked, during, my, birthday]\n",
       "27    [My, grandmother, is, the, love, of, my, life]\n",
       "28                              [enjoy, your, break]\n",
       "29                        [valentine, day, is, near]\n",
       "30                          [I, miss, you, so, much]\n",
       "31                                [throw, the, ball]\n",
       "32                        [My, life, is, so, boring]\n",
       "33                                  [she, said, yes]\n",
       "34                    [will, you, be, my, valentine]\n",
       "35                    [he, can, pitch, really, well]\n",
       "36                                 [dance, with, me]\n",
       "37                                 [I, am, starving]\n",
       "38                   [See, you, at, the, restaurant]\n",
       "39                              [I, like, to, laugh]\n",
       "40                              [I, will, go, dance]\n",
       "41                           [I, like, your, jacket]\n",
       "42                                    [i, miss, her]\n",
       "43        [what, is, your, favorite, baseball, game]\n",
       "44                                       [Good, job]\n",
       "45              [I, love, to, the, stars, and, back]\n",
       "46                    [What, you, did, was, awesome]\n",
       "47                                 [ha, ha, ha, lol]\n",
       "48                               [I, want, to, joke]\n",
       "49                                        [go, away]\n",
       "50                      [yesterday, we, lost, again]\n",
       "51                        [family, is, all, I, have]\n",
       "52               [you, are, failing, this, exercise]\n",
       "53                                      [Good, joke]\n",
       "54              [You, totally, deserve, this, prize]\n",
       "55                    [I, did, not, have, breakfast]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
